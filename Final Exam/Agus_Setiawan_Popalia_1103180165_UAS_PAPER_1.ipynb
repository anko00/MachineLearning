{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Agus Setiawan Popalia_1103180165_UAS PAPER 1",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Oh0xOE8Imqn57Qghzf0eZNfFj-MQJLgA",
      "authorship_tag": "ABX9TyPkb1uEI/chOe97Mo2Oxn0F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anko00/MachineLearning/blob/main/Final%20Exam/Agus_Setiawan_Popalia_1103180165_UAS_PAPER_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**EMA**\n",
        "\n",
        "*Pada class ema ini tidak ada eror dalam program saat di coba di reproduce jadi tidak di lakukan perubahan apapun*"
      ],
      "metadata": {
        "id": "CgWlneXM2cLc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpzFPffc1hFg"
      },
      "outputs": [],
      "source": [
        "class EMA:\n",
        "    def __init__(self, model, decay):\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        self.original = {}\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def __call__(self, model, num_updates):\n",
        "        decay = min(self.decay, (1.0 + num_updates) / (10.0 + num_updates))\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                new_average = (1.0 - decay) * param.data + decay * self.shadow[name]\n",
        "                self.shadow[name] = new_average.clone()\n",
        "\n",
        "    def assign(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                self.original[name] = param.data.clone()\n",
        "                param.data = self.shadow[name]\n",
        "\n",
        "    def resume(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                assert name in self.shadow\n",
        "                param.data = self.original[name]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATASET**\n",
        "\n",
        "*Pada bagian dataset, perubahan yang dilkukan terfokus pada path dari masing-masing dataset, hal ini di kerenakan saat di produce dan di pindahkan ke google drive saya, ada perubahan path. namun selain itu tidak ada perubahan yang di lakukan karena program berjalan sesuai dengan semestinya*"
      ],
      "metadata": {
        "id": "igSj4e2n2khh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class MnistDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, training=True, transform=None):\n",
        "        if training==True:\n",
        "            f = open('/content/drive/MyDrive/UASPAPER1/data/MNIST/raw/train-images-idx3-ubyte', 'rb')\n",
        "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "            f.close()\n",
        "            f = open('/content/drive/MyDrive/UASPAPER1/data/MNIST/raw/train-labels-idx1-ubyte', 'rb')\n",
        "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
        "            f.close()\n",
        "        else:\n",
        "            f = open('/content/drive/MyDrive/UASPAPER1/data/MNIST/raw/t10k-images-idx3-ubyte', 'rb')\n",
        "            xs = np.array(np.frombuffer(f.read(), np.uint8, offset=16))\n",
        "            f.close()\n",
        "            f = open('/content/drive/MyDrive/UASPAPER1/data/MNIST/raw/t10k-labels-idx1-ubyte', 'rb')\n",
        "            ys = np.array(np.frombuffer(f.read(), np.uint8, offset=8))\n",
        "            f.close()\n",
        "        xs = np.reshape(xs, (-1, 28, 28, 1)).astype(np.float32)\n",
        "        ys = ys.astype(np.int)\n",
        "        self.x_data = xs\n",
        "        self.y_data = ys\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = Image.fromarray(self.x_data[idx].reshape(28, 28))\n",
        "        y = torch.tensor(np.array(self.y_data[idx]))\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        x = transforms.ToTensor()(np.array(x)/255)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "LKlu0Fgf2ksr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRANSFORM**\n",
        "\n",
        "*Satu-satunya perubahan pada bagian ini adalah saat pengimporan torchvision.transform.fucntionfal yang awalnya diletakkan pada variabel F, setealh di reproduce di ubah menjadi XY, hal ini dilakukan untuk menghindari benturan dengan fungsi lain yang pada program ini juga diletakkan pada variabel F*"
      ],
      "metadata": {
        "id": "SZvEy2zP2ypg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torchvision.transforms.functional as XY\n",
        "\n",
        "class RandomRotation(object):\n",
        "    def __init__(self, degrees, seed=1):\n",
        "        self.degrees = (-degrees, degrees)\n",
        "        random.seed(seed)\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_params(degrees):\n",
        "        angle = random.uniform(degrees[0], degrees[1])\n",
        "        return angle\n",
        "\n",
        "    def __call__(self, img):\n",
        "        angle = self.get_params(self.degrees)\n",
        "        return XY.rotate(img, angle, False, False, None, None)"
      ],
      "metadata": {
        "id": "_6TKp0qn2yz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MK3**\n",
        "\n",
        "Tidak ada berubahan "
      ],
      "metadata": {
        "id": "KabOFjuY3R7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, bias=False)       # output becomes 26x26\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 48, 3, bias=False)      # output becomes 24x24\n",
        "        self.conv2_bn = nn.BatchNorm2d(48)\n",
        "        self.conv3 = nn.Conv2d(48, 64, 3, bias=False)      # output becomes 22x22\n",
        "        self.conv3_bn = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 80, 3, bias=False)      # output becomes 20x20\n",
        "        self.conv4_bn = nn.BatchNorm2d(80)\n",
        "        self.conv5 = nn.Conv2d(80, 96, 3, bias=False)      # output becomes 18x18\n",
        "        self.conv5_bn = nn.BatchNorm2d(96)\n",
        "        self.conv6 = nn.Conv2d(96, 112, 3, bias=False)     # output becomes 16x16\n",
        "        self.conv6_bn = nn.BatchNorm2d(112)\n",
        "        self.conv7 = nn.Conv2d(112, 128, 3, bias=False)    # output becomes 14x14\n",
        "        self.conv7_bn = nn.BatchNorm2d(128)\n",
        "        self.conv8 = nn.Conv2d(128, 144, 3, bias=False)    # output becomes 12x12\n",
        "        self.conv8_bn = nn.BatchNorm2d(144)\n",
        "        self.conv9 = nn.Conv2d(144, 160, 3, bias=False)    # output becomes 10x10\n",
        "        self.conv9_bn = nn.BatchNorm2d(160)\n",
        "        self.conv10 = nn.Conv2d(160, 176, 3, bias=False)   # output becomes 8x8\n",
        "        self.conv10_bn = nn.BatchNorm2d(176)\n",
        "        self.fc1 = nn.Linear(11264, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        conv6 = F.relu(self.conv6_bn(self.conv6(conv5)))\n",
        "        conv7 = F.relu(self.conv7_bn(self.conv7(conv6)))\n",
        "        conv8 = F.relu(self.conv8_bn(self.conv8(conv7)))\n",
        "        conv9 = F.relu(self.conv9_bn(self.conv9(conv8)))\n",
        "        conv10 = F.relu(self.conv10_bn(self.conv10(conv9)))\n",
        "        flat1 = torch.flatten(conv10.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)"
      ],
      "metadata": {
        "id": "4he9IAcM3SDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MK5**\n",
        "\n",
        "Tidak ada berubahan "
      ],
      "metadata": {
        "id": "1B3IQys43ZKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5, bias=False)\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5, bias=False)\n",
        "        self.conv2_bn = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 96, 5, bias=False)\n",
        "        self.conv3_bn = nn.BatchNorm2d(96)\n",
        "        self.conv4 = nn.Conv2d(96, 128, 5, bias=False)\n",
        "        self.conv4_bn = nn.BatchNorm2d(128)\n",
        "        self.conv5 = nn.Conv2d(128, 160, 5, bias=False)\n",
        "        self.conv5_bn = nn.BatchNorm2d(160)\n",
        "        self.fc1 = nn.Linear(10240, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n",
        "        flat5 = torch.flatten(conv5.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat5))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)"
      ],
      "metadata": {
        "id": "pqdx_XJ_3ZTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MK7**\n",
        "\n",
        "Tidak ada berubahan "
      ],
      "metadata": {
        "id": "yZEeBcog3eKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelM7(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelM7, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 48, 7, bias=False)    # output becomes 22x22\n",
        "        self.conv1_bn = nn.BatchNorm2d(48)\n",
        "        self.conv2 = nn.Conv2d(48, 96, 7, bias=False)   # output becomes 16x16\n",
        "        self.conv2_bn = nn.BatchNorm2d(96)\n",
        "        self.conv3 = nn.Conv2d(96, 144, 7, bias=False)  # output becomes 10x10\n",
        "        self.conv3_bn = nn.BatchNorm2d(144)\n",
        "        self.conv4 = nn.Conv2d(144, 192, 7, bias=False) # output becomes 4x4\n",
        "        self.conv4_bn = nn.BatchNorm2d(192)\n",
        "        self.fc1 = nn.Linear(3072, 10, bias=False)\n",
        "        self.fc1_bn = nn.BatchNorm1d(10)\n",
        "    def get_logits(self, x):\n",
        "        x = (x - 0.5) * 2.0\n",
        "        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n",
        "        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n",
        "        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n",
        "        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n",
        "        flat1 = torch.flatten(conv4.permute(0, 2, 3, 1), 1)\n",
        "        logits = self.fc1_bn(self.fc1(flat1))\n",
        "        return logits\n",
        "    def forward(self, x):\n",
        "        logits = self.get_logits(x)\n",
        "        return F.log_softmax(logits, dim=1)"
      ],
      "metadata": {
        "id": "9_Hs-t8E3fUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAIN**\n",
        "\n",
        "*Perubahan yang dilakukan pada bagian ini adalah penghapusan beberapa fungsi impor dari keseluruhan bagian kode yang telah di tulis ulang pada program ini sehingga tidak terpanggil 2 kali. selain itu juga di lakukan perubahan pada path karena perubahan yang terjadi setelah di reproduce dan juga prubahan terakhir yang dilakukan pada bagian ini adalah mengubah agar nilai-nilai varibel jika lupa di input pada awal pemanggilan dapat di lakukan pemanggilan mulai dan tidak lagi menggunakan aturan default yang telah di tetapkan seperti sebeelum di reproduce, nama variabel yang akan di panggil juga diubah menjadi lebih simpel sehingga dapat mudah dimengerti*"
      ],
      "metadata": {
        "id": "GsRnutOW3ibj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports -------------------------------------------------------------------------#\n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np \n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "\n",
        "def run(p_seed=0, p_epochs=150, p_kernel_size=5, p_logdir=\"temp\"):\n",
        "    # random number generator seed ------------------------------------------------#\n",
        "    SEED = p_seed\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    np.random.seed(SEED)\n",
        "\n",
        "    # kernel size of model --------------------------------------------------------#\n",
        "    KERNEL_SIZE = p_kernel_size\n",
        "\n",
        "    # number of epochs ------------------------------------------------------------#\n",
        "    NUM_EPOCHS = p_epochs\n",
        "\n",
        "    # file names ------------------------------------------------------------------#\n",
        "    if not os.path.exists(\"/content/drive/MyDrive/UASPAPER1/logs/%s\"%p_logdir):\n",
        "        os.makedirs(\"/content/drive/MyDrive/UASPAPER1/logs/%s\"%p_logdir)\n",
        "    OUTPUT_FILE = str(\"/content/drive/MyDrive/UASPAPER1/logs/%s/log%03d.out\"%(p_logdir,SEED))\n",
        "    MODEL_FILE = str(\"/content/drive/MyDrive/UASPAPER1/logs/%s/model%03d.pth\"%(p_logdir,SEED))\n",
        "\n",
        "    # enable GPU usage ------------------------------------------------------------#\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # data augmentation methods ---------------------------------------------------#\n",
        "    transform = transforms.Compose([\n",
        "        RandomRotation(20, seed=SEED),\n",
        "        transforms.RandomAffine(0, translate=(0.2, 0.2)),\n",
        "        ])\n",
        "\n",
        "    # data loader -----------------------------------------------------------------#\n",
        "    train_dataset = MnistDataset(training=True, transform=transform)\n",
        "    test_dataset = MnistDataset(training=False, transform=None)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=120, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # model selection -------------------------------------------------------------#\n",
        "    if(KERNEL_SIZE == 3):\n",
        "        model = ModelM3().to(device)\n",
        "    elif(KERNEL_SIZE == 5):\n",
        "        model = ModelM5().to(device)\n",
        "    elif(KERNEL_SIZE == 7):\n",
        "        model = ModelM7().to(device)\n",
        "\n",
        "    summary(model, (1, 28, 28))\n",
        "\n",
        "    # hyperparameter selection ----------------------------------------------------#\n",
        "    ema = EMA(model, decay=0.999)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
        "\n",
        "    # delete result file ----------------------------------------------------------#\n",
        "    f = open(OUTPUT_FILE, 'w')\n",
        "    f.close()\n",
        "\n",
        "    # global variables ------------------------------------------------------------#\n",
        "    g_step = 0\n",
        "    max_correct = 0\n",
        "\n",
        "    # training and evaluation loop ------------------------------------------------#\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # train process                                                            #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_corr = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.nll_loss(output, target)\n",
        "            train_pred = output.argmax(dim=1, keepdim=True)\n",
        "            train_corr += train_pred.eq(target.view_as(train_pred)).sum().item()\n",
        "            train_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            g_step += 1\n",
        "            ema(model, g_step)\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Train Epoch: {} [{:05d}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = 100 * train_corr / len(train_loader.dataset)\n",
        "\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # test process                                                             #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        model.eval()\n",
        "        ema.assign(model)\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total_pred = np.zeros(0)\n",
        "        total_target = np.zeros(0)\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                total_pred = np.append(total_pred, pred.cpu().numpy())\n",
        "                total_target = np.append(total_target, target.cpu().numpy())\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            if(max_correct < correct):\n",
        "                torch.save(model.state_dict(), MODEL_FILE)\n",
        "                max_correct = correct\n",
        "                print(\"Best accuracy! correct images: %5d\"%correct)\n",
        "        ema.resume(model)\n",
        "\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # output                                                                   #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        test_loss /= len(test_loader.dataset)\n",
        "        test_accuracy = 100 * correct / len(test_loader.dataset)\n",
        "        best_test_accuracy = 100 * max_correct / len(test_loader.dataset)\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%) (best: {:.2f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset), test_accuracy, best_test_accuracy))\n",
        "\n",
        "        f = open(OUTPUT_FILE, 'a')\n",
        "        f.write(\" %3d %12.6f %9.3f %12.6f %9.3f %9.3f\\n\"%(epoch, train_loss, train_accuracy, test_loss, test_accuracy, best_test_accuracy))\n",
        "        f.close()\n",
        "\n",
        "        #--------------------------------------------------------------------------#\n",
        "        # update learning rate scheduler                                           #\n",
        "        #--------------------------------------------------------------------------#\n",
        "        lr_scheduler.step()\n",
        "\n",
        "eeds: \")) \n",
        "p_epoch = int(input (\"Epoch: \"))\n",
        "p_trials = int(input (\"Trials: \"))\n",
        "p_kernel_size = int (input (\"Kernel size: \")) \n",
        "p_gpu = int(input (\"GPU: \")) \n",
        "p_logdir = input (\"Logdir: \")\n",
        "\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(p_gpu)\n",
        "\n",
        "for x in range (p_trials):\n",
        "  run(p_seed + x, p_epoch, p_kernel_size, p_logdir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-2FQPUS3kUc",
        "outputId": "17bb7213-19e7-44a6-a663-a20aa65bbaf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seeds: 0\n",
            "Epoch: 5\n",
            "Trials: 5\n",
            "Kernel size: 3\n",
            "GPU: 0\n",
            "Logdir: modelM3\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.657581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:992: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.644509\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.431458\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.324747\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.259744\n",
            "Best accuracy! correct images:  9837\n",
            "\n",
            "Test set: Average loss: 0.1619, Accuracy: 9837/10000 (98.37%) (best: 98.37%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.235940\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.210491\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.228506\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.151298\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.167080\n",
            "Best accuracy! correct images:  9886\n",
            "\n",
            "Test set: Average loss: 0.0985, Accuracy: 9886/10000 (98.86%) (best: 98.86%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.127794\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.150670\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.130251\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.082413\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.131678\n",
            "\n",
            "Test set: Average loss: 0.1041, Accuracy: 9837/10000 (98.37%) (best: 98.86%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.106520\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.102702\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.096546\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.137737\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.134460\n",
            "Best accuracy! correct images:  9891\n",
            "\n",
            "Test set: Average loss: 0.0515, Accuracy: 9891/10000 (98.91%) (best: 98.91%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.089080\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.039457\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.159233\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.078115\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.101541\n",
            "Best accuracy! correct images:  9903\n",
            "\n",
            "Test set: Average loss: 0.0593, Accuracy: 9903/10000 (99.03%) (best: 99.03%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.636028\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.647832\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.413704\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.371092\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.312717\n",
            "Best accuracy! correct images:  9855\n",
            "\n",
            "Test set: Average loss: 0.1321, Accuracy: 9855/10000 (98.55%) (best: 98.55%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.279296\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.204168\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.219688\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.138832\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.209977\n",
            "Best accuracy! correct images:  9894\n",
            "\n",
            "Test set: Average loss: 0.0764, Accuracy: 9894/10000 (98.94%) (best: 98.94%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.222111\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.198160\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.105505\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.105949\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.097200\n",
            "\n",
            "Test set: Average loss: 0.0640, Accuracy: 9882/10000 (98.82%) (best: 98.94%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.129771\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.120033\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.138586\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.095951\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.059565\n",
            "\n",
            "Test set: Average loss: 0.0637, Accuracy: 9893/10000 (98.93%) (best: 98.94%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.106627\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.104141\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.109954\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.082695\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.066076\n",
            "Best accuracy! correct images:  9935\n",
            "\n",
            "Test set: Average loss: 0.0500, Accuracy: 9935/10000 (99.35%) (best: 99.35%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.781280\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.692152\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.421331\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.367163\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.257468\n",
            "Best accuracy! correct images:  9903\n",
            "\n",
            "Test set: Average loss: 0.1202, Accuracy: 9903/10000 (99.03%) (best: 99.03%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.252424\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.193160\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.233927\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.214553\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.141100\n",
            "\n",
            "Test set: Average loss: 0.1153, Accuracy: 9847/10000 (98.47%) (best: 99.03%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.139321\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.246029\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.133498\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.132394\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.119488\n",
            "Best accuracy! correct images:  9916\n",
            "\n",
            "Test set: Average loss: 0.0648, Accuracy: 9916/10000 (99.16%) (best: 99.16%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.134954\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.118088\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.117211\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.131605\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.110608\n",
            "\n",
            "Test set: Average loss: 0.0752, Accuracy: 9908/10000 (99.08%) (best: 99.16%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.088950\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.119878\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.104338\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.062575\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.074147\n",
            "\n",
            "Test set: Average loss: 0.0526, Accuracy: 9896/10000 (98.96%) (best: 99.16%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.845584\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.734352\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.437420\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.326101\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.247609\n",
            "Best accuracy! correct images:  9885\n",
            "\n",
            "Test set: Average loss: 0.1193, Accuracy: 9885/10000 (98.85%) (best: 98.85%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.216039\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.256882\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.280726\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.194597\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.140175\n",
            "\n",
            "Test set: Average loss: 0.1018, Accuracy: 9880/10000 (98.80%) (best: 98.85%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.186126\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.136455\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.108124\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.074210\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.144340\n",
            "Best accuracy! correct images:  9894\n",
            "\n",
            "Test set: Average loss: 0.0642, Accuracy: 9894/10000 (98.94%) (best: 98.94%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.071753\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.145950\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.105642\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.091366\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.082137\n",
            "Best accuracy! correct images:  9927\n",
            "\n",
            "Test set: Average loss: 0.0493, Accuracy: 9927/10000 (99.27%) (best: 99.27%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.062197\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.120297\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.080788\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.126620\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.091405\n",
            "\n",
            "Test set: Average loss: 0.0468, Accuracy: 9926/10000 (99.26%) (best: 99.27%)\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             288\n",
            "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
            "            Conv2d-3           [-1, 48, 24, 24]          13,824\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "            Conv2d-5           [-1, 64, 22, 22]          27,648\n",
            "       BatchNorm2d-6           [-1, 64, 22, 22]             128\n",
            "            Conv2d-7           [-1, 80, 20, 20]          46,080\n",
            "       BatchNorm2d-8           [-1, 80, 20, 20]             160\n",
            "            Conv2d-9           [-1, 96, 18, 18]          69,120\n",
            "      BatchNorm2d-10           [-1, 96, 18, 18]             192\n",
            "           Conv2d-11          [-1, 112, 16, 16]          96,768\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "           Conv2d-13          [-1, 128, 14, 14]         129,024\n",
            "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
            "           Conv2d-15          [-1, 144, 12, 12]         165,888\n",
            "      BatchNorm2d-16          [-1, 144, 12, 12]             288\n",
            "           Conv2d-17          [-1, 160, 10, 10]         207,360\n",
            "      BatchNorm2d-18          [-1, 160, 10, 10]             320\n",
            "           Conv2d-19            [-1, 176, 8, 8]         253,440\n",
            "      BatchNorm2d-20            [-1, 176, 8, 8]             352\n",
            "           Linear-21                   [-1, 10]         112,640\n",
            "      BatchNorm1d-22                   [-1, 10]              20\n",
            "================================================================\n",
            "Total params: 1,124,180\n",
            "Trainable params: 1,124,180\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.74\n",
            "Params size (MB): 4.29\n",
            "Estimated Total Size (MB): 8.03\n",
            "----------------------------------------------------------------\n",
            "Train Epoch: 0 [00000/60000 (0%)]\tLoss: 2.558000\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.653399\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.420209\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.381024\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.298903\n",
            "Best accuracy! correct images:  9863\n",
            "\n",
            "Test set: Average loss: 0.1451, Accuracy: 9863/10000 (98.63%) (best: 98.63%)\n",
            "\n",
            "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 0.319992\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.284144\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.230777\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.164753\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.167446\n",
            "Best accuracy! correct images:  9900\n",
            "\n",
            "Test set: Average loss: 0.0762, Accuracy: 9900/10000 (99.00%) (best: 99.00%)\n",
            "\n",
            "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 0.149612\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.145609\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.162328\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.117442\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.118292\n",
            "\n",
            "Test set: Average loss: 0.0714, Accuracy: 9898/10000 (98.98%) (best: 99.00%)\n",
            "\n",
            "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.149527\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.141583\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.095074\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.153903\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.078501\n",
            "\n",
            "Test set: Average loss: 0.0531, Accuracy: 9892/10000 (98.92%) (best: 99.00%)\n",
            "\n",
            "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.119296\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.168053\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.069165\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.072366\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.123790\n",
            "\n",
            "Test set: Average loss: 0.1034, Accuracy: 9799/10000 (97.99%) (best: 99.00%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TEST**\n",
        "\n",
        "*Perubahan yang di lakukan pada bagian ini hanya terletak pada perubahan path, dan juga perubahan nama variabel sehingga lebih mudah dan lebih mirip dengan perubahan yang telah di lakukan pada bagian train. dan juga mengubah yang awalnya jika variabel tidak dimasukkan akan diambil dari default, sekarang pengguna harus memasukkan nilai variabel sebelum di run, jika tidak program tidak akan di jalankan*"
      ],
      "metadata": {
        "id": "ebqBqRCOIkl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports ---------------------------------------------------------------------#\n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np \n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def run(p_seed=0, p_kernel_size=5, p_logdir=\"temp\"):\n",
        "\n",
        "    # enable GPU usage ------------------------------------------------------------#\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda == False:\n",
        "        print(\"WARNING: CPU will be used for training.\")\n",
        "        exit(0)\n",
        "\n",
        "    # data loader -----------------------------------------------------------------#\n",
        "    test_dataset = MnistDataset(training=False, transform=None)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # model selection -------------------------------------------------------------#\n",
        "    if(p_kernel_size == 3):\n",
        "        model1 = ModelM3().to(device)\n",
        "    elif(p_kernel_size == 5):\n",
        "        model1 = ModelM5().to(device)\n",
        "    elif(p_kernel_size == 7):\n",
        "        model1 = ModelM7().to(device)\n",
        "\n",
        "    model1.load_state_dict(torch.load(\"/content/drive/MyDrive/UASPAPER1/logs/%s/model%03d.pth\"%(p_logdir,p_seed)))\n",
        "\n",
        "    model1.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    wrong_images = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model1(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            wrong_images.extend(np.nonzero(~pred.eq(target.view_as(pred)).cpu().numpy())[0]+(100*batch_idx))\n",
        "\n",
        "    np.savetxt(\"/content/drive/MyDrive/UASPAPER1/logs/%s/wrong%03d.txt\"%(p_logdir,p_seed), wrong_images, fmt=\"%d\")\n",
        "    print(len(wrong_images), wrong_images)\n",
        "\n",
        "p_logdir = input (\"Logdir: \") \n",
        "p_seed = int(input (\"Seeds: \")) \n",
        "p_trials = int(input (\"Trials: \")) \n",
        "p_kernel_size = int (input (\"Kernel size:  \")) \n",
        "\n",
        "for q in range(p_trials):\n",
        "    run(p_seed + q, p_kernel_size,p_logdir)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwhi452bIWJQ",
        "outputId": "9f209fbd-ca77-4038-89cd-eaa35c593176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logdir: modelM3\n",
            "Seeds: 0\n",
            "Trials: 5\n",
            "Kernel size:  3\n",
            "97 [321, 360, 445, 447, 582, 625, 947, 965, 1033, 1045, 1226, 1232, 1260, 1299, 1364, 1393, 1441, 1681, 1716, 1737, 1748, 1878, 1901, 1911, 1940, 2035, 2040, 2093, 2118, 2130, 2135, 2225, 2293, 2338, 2363, 2447, 2454, 2462, 2532, 2582, 2597, 2654, 2836, 2930, 3030, 3062, 3073, 3343, 3365, 3412, 3422, 3475, 3534, 3558, 3846, 3946, 3976, 4092, 4152, 4207, 4443, 4699, 4860, 5082, 5677, 5937, 6554, 6558, 6559, 6569, 6571, 6576, 6597, 6625, 7520, 7574, 8092, 8095, 8275, 8279, 8408, 8527, 9009, 9015, 9620, 9627, 9638, 9639, 9642, 9664, 9669, 9672, 9679, 9698, 9729, 9754, 9839]\n",
            "65 [359, 445, 449, 582, 625, 882, 938, 1050, 1114, 1226, 1232, 1260, 1299, 1393, 1621, 1716, 1737, 1901, 1911, 2040, 2130, 2135, 2182, 2189, 2293, 2308, 2462, 2534, 2597, 2654, 3073, 3225, 3365, 3422, 3558, 3821, 3838, 3906, 3976, 4018, 4284, 4369, 4699, 4740, 4761, 4823, 5937, 6554, 6571, 6576, 6625, 8275, 8279, 8316, 8408, 8527, 9009, 9015, 9019, 9024, 9638, 9679, 9698, 9729, 9754]\n",
            "84 [104, 193, 321, 359, 445, 449, 582, 593, 625, 659, 965, 1039, 1050, 1232, 1247, 1260, 1299, 1393, 1551, 1681, 1737, 1901, 1911, 1940, 2040, 2090, 2118, 2130, 2135, 2182, 2189, 2293, 2406, 2454, 2462, 2597, 2654, 2939, 3073, 3365, 3412, 3422, 3475, 3534, 3762, 3796, 3821, 3846, 3906, 3946, 4027, 4571, 4699, 4761, 4814, 4823, 5677, 5833, 5937, 5955, 6554, 6558, 6571, 6576, 6597, 6625, 7574, 8095, 8275, 8279, 8408, 8527, 9168, 9530, 9620, 9638, 9642, 9664, 9672, 9679, 9698, 9729, 9811, 9839]\n",
            "73 [321, 359, 445, 447, 582, 625, 674, 947, 1226, 1232, 1299, 1364, 1393, 1441, 1551, 1737, 1782, 1859, 1901, 1911, 2035, 2040, 2118, 2130, 2135, 2182, 2293, 2454, 2462, 2597, 2654, 3062, 3073, 3132, 3343, 3365, 3412, 3422, 3520, 3558, 3762, 3846, 3906, 3946, 4065, 4201, 4207, 4571, 4699, 4740, 4823, 4860, 5265, 5937, 6554, 6555, 6558, 6576, 6597, 6625, 6755, 8275, 8279, 8382, 8408, 8527, 9009, 9664, 9669, 9672, 9679, 9698, 9729]\n",
            "100 [8, 195, 359, 449, 582, 625, 646, 720, 726, 882, 938, 947, 1032, 1114, 1226, 1232, 1260, 1299, 1328, 1378, 1621, 1681, 1737, 1754, 1847, 1901, 1911, 2035, 2040, 2118, 2130, 2135, 2162, 2182, 2237, 2293, 2308, 2358, 2462, 2488, 2597, 2686, 2823, 2927, 2930, 3005, 3073, 3129, 3132, 3225, 3330, 3448, 3475, 3534, 3549, 3558, 3654, 3762, 3821, 3846, 3893, 3906, 3962, 3985, 3994, 4007, 4300, 4369, 4443, 4551, 4740, 4761, 4823, 4990, 5833, 5937, 5955, 5981, 5997, 6065, 6172, 6569, 6571, 6576, 6625, 6746, 8275, 8279, 8316, 8387, 8527, 9009, 9015, 9024, 9664, 9729, 9749, 9754, 9762, 9850]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Homo Ensembel**\n",
        "\n",
        "*Perubahan yang dilakukan pada bagian ini adalah perubahan cara pemanggilan kernel sehingga lebih simpel dan harus selalu dimasukkan sebelum program di mulai, selain itu juga adanya penambahan input trials yang nantinya akan menjadi pengganti yang mana sebelumnya nilainya hanya di fix 10, dengan adanya input trials ini menjadikkan program ini bisa lebih banyak melakukan perulangan dan tidak terbatas di 10 melainkan terbatas sesuai dengan keinginan pengguna dalam menjalankan trialsnya. dan juga ada perubahan pada path.*"
      ],
      "metadata": {
        "id": "BqDrPyK8QLnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import argparse\n",
        "\n",
        "cnt = 1\n",
        "best = 10000\n",
        "curr = 10000\n",
        "\n",
        "p_kernel_size = int (input (\"Kernel size: \")) \n",
        "p_trials = int(input (\"Trials: \")) \n",
        "KERNEL_SIZE = p_kernel_size\n",
        "\n",
        "for i in range(p_trials):\n",
        "    for j in range(i+1,p_trials):\n",
        "        for k in range(j+1,p_trials):\n",
        "            w1 = np.loadtxt(\"/content/drive/MyDrive/UASPAPER1/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, i)).astype(np.int)\n",
        "            w2 = np.loadtxt(\"/content/drive/MyDrive/UASPAPER1/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, j)).astype(np.int)\n",
        "            w3 = np.loadtxt(\"/content/drive/MyDrive/UASPAPER1/logs/modelM%d/wrong%03d.txt\"%(KERNEL_SIZE, k)).astype(np.int)\n",
        "\n",
        "            board = np.zeros((10000))\n",
        "            board[w1] += 1\n",
        "            board[w2] += 1\n",
        "            board[w3] += 1\n",
        "            board = board // 2\n",
        "            curr = np.sum(board)\n",
        "            if curr < best:\n",
        "                best = curr\n",
        "            print(\"%4d %4d %4d %4d %4d %4d\"%(cnt, len(w1), len(w2), len(w3), curr, best))\n",
        "            cnt += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inzSYcBqQTSu",
        "outputId": "726ccca3-60af-42c4-f0f7-9f705cb2db75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel size: 3\n",
            "Trials: 5\n",
            "   1   97   65   84   71   71\n",
            "   2   97   65   73   66   66\n",
            "   3   97   65  100   69   66\n",
            "   4   97   84   73   75   66\n",
            "   5   97   84  100   75   66\n",
            "   6   97   73  100   71   66\n",
            "   7   65   84   73   60   60\n",
            "   8   65   84  100   67   60\n",
            "   9   65   73  100   62   60\n",
            "  10   84   73  100   65   60\n"
          ]
        }
      ]
    }
  ]
}